{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5024a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/logs/sub-24_blk-2.log\n",
      "../data/logs/sub-24_blk-4.log\n",
      "../data/logs/sub-24_blk-0.log\n",
      "../data/logs/sub-24_blk-1.log\n",
      "../data/logs/sub-24_blk-3.log\n",
      "Successfully matched marks and tags :-)\n",
      "Extracting parameters from ../data/raw/sub-24.vhdr...\n",
      "Setting channel info structure...\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S 11', 'Stimulus/S 12', 'Stimulus/S 13', 'Stimulus/S 21', 'Stimulus/S 22', 'Stimulus/S 23', 'Stimulus/S 31', 'Stimulus/S 32', 'Stimulus/S 33']\n",
      "../data/logs/sub-24_blk-2.log\n",
      "../data/logs/sub-24_blk-4.log\n",
      "../data/logs/sub-24_blk-0.log\n",
      "../data/logs/sub-24_blk-1.log\n",
      "../data/logs/sub-24_blk-3.log\n",
      "Successfully matched marks and tags :-)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 183>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m raw \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_raw(eeg_fpath)\n\u001b[1;32m    182\u001b[0m events, event_ids \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mevents_from_annotations(raw)\n\u001b[0;32m--> 183\u001b[0m \u001b[43madd_stream_to_event_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36madd_stream_to_event_tags\u001b[0;34m(events, sub)\u001b[0m\n\u001b[1;32m     27\u001b[0m hier_tags \u001b[38;5;241m=\u001b[39m make_tags_hierarchical(streams, tags)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Now add hierarchical tags to events object\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m hier_events \u001b[38;5;241m=\u001b[39m \u001b[43madd_hierarchical_tags_to_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhier_tags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hier_events\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36madd_hierarchical_tags_to_events\u001b[0;34m(events, hier_tags)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(events)):\n\u001b[1;32m    174\u001b[0m     hier_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(events[i])\n\u001b[0;32m--> 175\u001b[0m     hier_event[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mhier_tags\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    176\u001b[0m     hier_events\u001b[38;5;241m.\u001b[39mappend(hier_event)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hier_events\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# def add_stream_to_event_tags(events, sub):\n",
    "# Get marks and streams\n",
    "tags = get_tags(events)\n",
    "marks, streams = get_marks_and_streams_from_log_file(sub)\n",
    "\n",
    "# Find diff between marks and tags\n",
    "diffs = diff(marks, tags)\n",
    "indexes_to_drop_from_marks, indexes_to_drop_from_tags = get_drop_indexes(diffs)\n",
    "marks = apply_diff(marks, indexes_to_drop_from_marks)\n",
    "tags = apply_diff(tags, indexes_to_drop_from_tags)\n",
    "\n",
    "# Check\n",
    "if tags != marks:\n",
    "    raise ValueError('Event tags do not match log file tags!')\n",
    "else:\n",
    "    print('Successfully matched marks and tags :-)')\n",
    "\n",
    "# Now apply the diffs the list of stream sides\n",
    "streams = apply_diff(streams, indexes_to_drop_from_marks)\n",
    "\n",
    "# Now add streams to event tags\n",
    "hier_tags = make_tags_hierarchical(streams, tags)\n",
    "\n",
    "# Now make original events object match the new tags\n",
    "events = apply_diff(events.tolist(), indexes_to_drop_from_tags)\n",
    "events = np.array(events)\n",
    "\n",
    "# Now add hierarchical tags to events object\n",
    "hier_events = add_hierarchical_tags_to_events(events, hier_tags)\n",
    "\n",
    "#     return hier_events\n",
    "\n",
    "def get_drop_indexes(diffs):\n",
    "    indexes_to_drop_from_tags = []\n",
    "    indexes_to_drop_from_marks = []\n",
    "\n",
    "    for i, diff in enumerate(diffs):\n",
    "        change = diff[0]\n",
    "        if change == 'addition': # tag is found in tags but not in marks\n",
    "            indexes_to_drop_from_tags.append(i)\n",
    "        elif change == 'removal':\n",
    "            indexes_to_drop_from_marks.append(i)\n",
    "    \n",
    "    return indexes_to_drop_from_marks, indexes_to_drop_from_tags\n",
    "\n",
    "def apply_diff(l, indexes):\n",
    "    for index in sorted(indexes, reverse=True):\n",
    "        del l[index]\n",
    "    return l\n",
    "\n",
    "def compute_lcs_len(text1, text2):\n",
    "    \"\"\"Computes a table of f(i, j) results.\"\"\"\n",
    "    n = len(text1)\n",
    "    m = len(text2)\n",
    "\n",
    "    # We store the results in a (n + 1) x (m + 1) matrix. The +1s are to\n",
    "    # allocate space for the empty strings. Cell [i][j] will cache the\n",
    "    # result of f(i, j).\n",
    "    lcs = [[None for _ in range(m + 1)]\n",
    "               for _ in range(n + 1)]\n",
    "\n",
    "    # We then fill the matrix by going through all rows, using the fact\n",
    "    # that each call only needs results from the previous (i - 1) or\n",
    "    # same (i) row, and from the previous (j - 1) or same (j) column.\n",
    "    for i in range(0, n + 1):\n",
    "        for j in range(0, m + 1):\n",
    "          # The remaining code is exactly the same recursion as before, but\n",
    "          # we do not make recursive calls and instead use the results cached\n",
    "          # in the matrix.\n",
    "            if i == 0 or j == 0:\n",
    "                lcs[i][j] = 0\n",
    "            elif text1[i - 1] == text2[j - 1]:\n",
    "                lcs[i][j] = 1 + lcs[i - 1][j - 1]\n",
    "            else:\n",
    "                lcs[i][j] = max(lcs[i - 1][j], lcs[i][j - 1])\n",
    "\n",
    "    return lcs\n",
    "\n",
    "def diff(text1, text2):\n",
    "    \"\"\"Computes the optimal diff of the two given inputs.\n",
    "\n",
    "    The result is a list where all elements are Removals, Additions or\n",
    "    Unchanged elements.\n",
    "    \"\"\"\n",
    "    lcs = compute_lcs_len(text1, text2)\n",
    "    results = []\n",
    "\n",
    "    text1 = list(text1)\n",
    "    text2 = list(text2)\n",
    "    \n",
    "    i = len(text1)\n",
    "    j = len(text2)\n",
    "\n",
    "  # We iterate until we reach the end of both texts.\n",
    "    while i != 0 or j != 0:\n",
    "        # If we reached the end of one of text1 (i == 0) or text2 (j == 0),\n",
    "        # then we just need to print the remaining additions and removals.\n",
    "        if i == 0:\n",
    "            results.append(('addition', text2[j - 1]))\n",
    "            j -= 1\n",
    "        elif j == 0:\n",
    "            results.append(('removal', text1[i - 1]))\n",
    "            i -= 1\n",
    "        # Otherwise there's still parts of text1 and text2 left. If the\n",
    "        # currently considered parts are equal, then we found an unchanged\n",
    "        # part which belongs to the longest common subsequence.\n",
    "        elif text1[i - 1] == text2[j - 1]:\n",
    "            results.append(('unchanged', text1[i - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        # In any other case, we go in the direction of the longest common\n",
    "        # subsequence.\n",
    "        elif lcs[i - 1][j] <= lcs[i][j - 1]:\n",
    "            results.append(('addition', text2[j - 1]))\n",
    "            j -= 1\n",
    "        else:\n",
    "            results.append(('removal', text1[i - 1]))\n",
    "            i -= 1\n",
    "\n",
    "    # Reverse results because we iterated over the texts from the end but\n",
    "    # want the results to be in forward order.\n",
    "    return list(reversed(results))\n",
    "\n",
    "def get_tags(events):\n",
    "    tags = []\n",
    "    for i in range(1, len(events)):\n",
    "        tags.append(events[i][2])\n",
    "    return tags\n",
    "    \n",
    "def get_marks_and_streams_from_log_file(sub):\n",
    "    # Get events from log files\n",
    "    log_dir = '../data/logs'\n",
    "    logs = pd.DataFrame()\n",
    "\n",
    "    for fpath in list(glob.glob(f'{log_dir}/sub-{sub}_*.log')):\n",
    "        print(fpath)\n",
    "\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(fpath):\n",
    "            log = pd.read_csv(fpath)\n",
    "            logs = pd.concat([logs, log])\n",
    "\n",
    "    logs = logs.sort_values(by = ['block_num', 'seq_num', 'tone_num'])\n",
    "    logs = logs.reset_index()\n",
    "    marks = list(logs.mark)\n",
    "    streams = logs.stream\n",
    "\n",
    "    return marks, streams\n",
    "\n",
    "def make_tags_hierarchical(streams, tags):\n",
    "\n",
    "    # Change stream string value from 'r' and 'l' into 1 and 2\n",
    "    stream_tag = streams.replace(['r', 'l'], [1, 2])\n",
    "    stream_tag = list(stream_tag)\n",
    "\n",
    "    # Concat stream tags with event tags\n",
    "    hier_tags = []\n",
    "    hier_tags.insert(0, 99999)\n",
    "    for stream, tag in zip(stream_tag, tags):\n",
    "        hier_tag = int(str(stream) + str(tag))\n",
    "        hier_tags.append(hier_tag)\n",
    "\n",
    "    return hier_tags\n",
    "\n",
    "def add_hierarchical_tags_to_events(events, hier_tags):\n",
    "    hier_events = []\n",
    "    for i in range(0, len(events)):\n",
    "        hier_event = list(events[i])\n",
    "        hier_event[2] = hier_tags[i]\n",
    "        hier_events.append(hier_event)\n",
    "    return hier_events\n",
    "\n",
    "sub = 24\n",
    "eeg_fpath = '../data/raw/sub-24.vhdr'\n",
    "raw = mne.io.read_raw(eeg_fpath)\n",
    "events, event_ids = mne.events_from_annotations(raw)\n",
    "# add_stream_to_event_tags(events, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a474ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       0,        0,    99999],\n",
       "       [  420922,        0,       12],\n",
       "       [  426687,        0,       12],\n",
       "       ...,\n",
       "       [17217970,        0,       13],\n",
       "       [17223730,        0,       23],\n",
       "       [17229495,        0,       23]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "events_list = events.tolist()\n",
    "np.array(events_list)\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8ffcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from ../data/raw/sub-9.vhdr...\n",
      "Setting channel info structure...\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S 11', 'Stimulus/S 12', 'Stimulus/S 13', 'Stimulus/S 21', 'Stimulus/S 22', 'Stimulus/S 23', 'Stimulus/S 31', 'Stimulus/S 32', 'Stimulus/S 33']\n",
      "../data/logs/sub-9_blk-0.log\n",
      "../data/logs/sub-9_blk-3.log\n",
      "../data/logs/sub-9_blk-2.log\n",
      "../data/logs/sub-9_blk-4.log\n",
      "../data/logs/sub-9_blk-1.log\n",
      "Successfully matched marks and tags :-)\n"
     ]
    }
   ],
   "source": [
    "sub = 9\n",
    "eeg_fpath = '../data/raw/sub-9.vhdr'\n",
    "raw = mne.io.read_raw(eeg_fpath)\n",
    "events, event_ids = mne.events_from_annotations(raw)\n",
    "\n",
    "# Get marks and streams\n",
    "tags = get_tags(events)\n",
    "marks, streams = get_marks_and_streams_from_log_file(sub)\n",
    "\n",
    "# Find diff between marks and tags\n",
    "diffs = diff(marks, tags)\n",
    "indexes_to_drop_from_marks, indexes_to_drop_from_tags = get_drop_indexes(diffs)\n",
    "marks = apply_diff(marks, indexes_to_drop_from_marks)\n",
    "tags = apply_diff(tags, indexes_to_drop_from_tags)\n",
    "\n",
    "# Check\n",
    "if tags != marks:\n",
    "    raise ValueError('Event tags do not match log file tags!')\n",
    "else:\n",
    "    print('Successfully matched marks and tags :-)')\n",
    "    \n",
    "# Now apply the diffs the list of stream sides\n",
    "streams = apply_diff(streams, indexes_to_drop_from_marks)\n",
    "\n",
    "# Now add streams to event tags\n",
    "hier_tags = make_tags_hierarchical(streams, tags)\n",
    "\n",
    "# Now add hierarchical tags to events object\n",
    "hier_events = add_hierarchical_tags_to_events(events, hier_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aeec816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def get_drop_indexes(diffs):\n",
    "    indexes_to_drop_from_tags = []\n",
    "    indexes_to_drop_from_marks = []\n",
    "\n",
    "    for i, diff in enumerate(diffs):\n",
    "        change = diff[0]\n",
    "        if change == 'addition': # tag is found in tags but not in marks\n",
    "            indexes_to_drop_from_tags.append(i)\n",
    "        elif change == 'removal':\n",
    "            indexes_to_drop_from_marks.append(i)\n",
    "    \n",
    "    return(indexes_to_drop_from_marks, indexes_to_drop_from_tags)\n",
    "\n",
    "def apply_diff(l, indexes):\n",
    "    for index in sorted(indexes, reverse=True):\n",
    "        del l[index]\n",
    "    return(l)\n",
    "\n",
    "def compute_lcs_len(text1, text2):\n",
    "    \"\"\"Computes a table of f(i, j) results.\"\"\"\n",
    "    n = len(text1)\n",
    "    m = len(text2)\n",
    "\n",
    "    # We store the results in a (n + 1) x (m + 1) matrix. The +1s are to\n",
    "    # allocate space for the empty strings. Cell [i][j] will cache the\n",
    "    # result of f(i, j).\n",
    "    lcs = [[None for _ in range(m + 1)]\n",
    "               for _ in range(n + 1)]\n",
    "\n",
    "    # We then fill the matrix by going through all rows, using the fact\n",
    "    # that each call only needs results from the previous (i - 1) or\n",
    "    # same (i) row, and from the previous (j - 1) or same (j) column.\n",
    "    for i in range(0, n + 1):\n",
    "        for j in range(0, m + 1):\n",
    "          # The remaining code is exactly the same recursion as before, but\n",
    "          # we do not make recursive calls and instead use the results cached\n",
    "          # in the matrix.\n",
    "            if i == 0 or j == 0:\n",
    "                lcs[i][j] = 0\n",
    "            elif text1[i - 1] == text2[j - 1]:\n",
    "                lcs[i][j] = 1 + lcs[i - 1][j - 1]\n",
    "            else:\n",
    "                lcs[i][j] = max(lcs[i - 1][j], lcs[i][j - 1])\n",
    "\n",
    "    return lcs\n",
    "\n",
    "def diff(text1, text2):\n",
    "    \"\"\"Computes the optimal diff of the two given inputs.\n",
    "\n",
    "    The result is a list where all elements are Removals, Additions or\n",
    "    Unchanged elements.\n",
    "    \"\"\"\n",
    "    lcs = compute_lcs_len(text1, text2)\n",
    "    results = []\n",
    "\n",
    "    text1 = list(text1)\n",
    "    text2 = list(text2)\n",
    "    \n",
    "    i = len(text1)\n",
    "    j = len(text2)\n",
    "\n",
    "  # We iterate until we reach the end of both texts.\n",
    "    while i != 0 or j != 0:\n",
    "        # If we reached the end of one of text1 (i == 0) or text2 (j == 0),\n",
    "        # then we just need to print the remaining additions and removals.\n",
    "        if i == 0:\n",
    "            results.append(('addition', text2[j - 1]))\n",
    "            j -= 1\n",
    "        elif j == 0:\n",
    "            results.append(('removal', text1[i - 1]))\n",
    "            i -= 1\n",
    "        # Otherwise there's still parts of text1 and text2 left. If the\n",
    "        # currently considered parts are equal, then we found an unchanged\n",
    "        # part which belongs to the longest common subsequence.\n",
    "        elif text1[i - 1] == text2[j - 1]:\n",
    "            results.append(('unchanged', text1[i - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        # In any other case, we go in the direction of the longest common\n",
    "        # subsequence.\n",
    "        elif lcs[i - 1][j] <= lcs[i][j - 1]:\n",
    "            results.append(('addition', text2[j - 1]))\n",
    "            j -= 1\n",
    "        else:\n",
    "            results.append(('removal', text1[i - 1]))\n",
    "            i -= 1\n",
    "\n",
    "    # Reverse results because we iterated over the texts from the end but\n",
    "    # want the results to be in forward order.\n",
    "    return list(reversed(results))\n",
    "\n",
    "def get_tags(events):\n",
    "    tags = []\n",
    "    for i in range(1, len(events)):\n",
    "        tags.append(events[i][2])\n",
    "    return tags\n",
    "    \n",
    "def get_marks_and_streams_from_log_file(sub):\n",
    "    # Get events from log files\n",
    "    log_dir = '../data/logs'\n",
    "    logs = pd.DataFrame()\n",
    "\n",
    "    for fpath in list(glob.glob(f'{log_dir}/sub-{sub}_*.log')):\n",
    "        print(fpath)\n",
    "\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(fpath):\n",
    "            log = pd.read_csv(fpath)\n",
    "            logs = pd.concat([logs, log])\n",
    "\n",
    "    logs = logs.sort_values(by = ['block_num', 'seq_num', 'tone_num'])\n",
    "    logs = logs.reset_index()\n",
    "    marks = list(logs.mark)\n",
    "    streams = logs.stream\n",
    "\n",
    "    return(marks, streams)\n",
    "\n",
    "def make_tags_hierarchical(streams, tags):\n",
    "\n",
    "    # Change stream string value from 'r' and 'l' into 1 and 2\n",
    "    stream_tag = streams.replace(['r', 'l'], [1, 2])\n",
    "    stream_tag = list(stream_tag)\n",
    "\n",
    "    # Concat stream tags with event tags\n",
    "    hier_tags = []\n",
    "    hier_tags.insert(0, 99999)\n",
    "    for stream, tag in zip(stream_tag, tags):\n",
    "        hier_tag = int(str(stream) + str(tag))\n",
    "        hier_tags.append(hier_tag)\n",
    "\n",
    "    return(hier_tags)\n",
    "\n",
    "def add_hierarchical_tags_to_events(events, hier_tags):\n",
    "    hier_events = []\n",
    "    for i in range(0, len(events)):\n",
    "        hier_event = list(events[i])\n",
    "        hier_event[2] = hier_tags[i]\n",
    "        hier_events.append(hier_event)\n",
    "    return(hier_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367643d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805673a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c77cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85211e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09b59540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing from terminal \n",
    "# from util.io.add_stream_to_event_tags import *\n",
    "import mne\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "        \n",
    "def add_stream_to_event_tags(events, sub):\n",
    "\n",
    "    # Extract event tags\n",
    "    tags = []\n",
    "    for i in range(1, len(events)):\n",
    "        tags.append(events[i][2])\n",
    "        \n",
    "    # Get marks from log files\n",
    "    marks, streams = get_marks_and_streams_from_log_file(sub)\n",
    "\n",
    "    # Find the indexes that match event and log tags up\n",
    "    window = 20\n",
    "    tags_i, marks_i = get_index_of_match(tags, marks, window)\n",
    "\n",
    "    # Trim marks to match event tags\n",
    "    start_i = marks_i\n",
    "    end_i = marks_i + len(tags)\n",
    "    marks = marks[start_i:end_i]\n",
    "    streams = streams[start_i:end_i]\n",
    "\n",
    "    # Add stream to tag\n",
    "    hier_tags = make_tags_hierarchical(streams, tags)\n",
    "\n",
    "    # Add hierarchical tags to events object\n",
    "    hier_events = add_hierarchical_tags_to_events(events, hier_tags)\n",
    "\n",
    "    return(hier_events)\n",
    "\n",
    "def get_tags(events):\n",
    "    tags = []\n",
    "    for i in range(1, len(events)):\n",
    "        tags.append(events[i][2])\n",
    "    return tags\n",
    "    \n",
    "def get_marks_and_streams_from_log_file(sub):\n",
    "    # Get events from log files\n",
    "    log_dir = '../data/logs'\n",
    "    logs = pd.DataFrame()\n",
    "\n",
    "    for fpath in list(glob.glob(f'{log_dir}/sub-{sub}_*.log')):\n",
    "        print(fpath)\n",
    "\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(fpath):\n",
    "            log = pd.read_csv(fpath)\n",
    "            logs = pd.concat([logs, log])\n",
    "\n",
    "    logs = logs.sort_values(by = ['block_num', 'seq_num', 'tone_num'])\n",
    "    logs = logs.reset_index()\n",
    "    marks = list(logs.mark)\n",
    "    streams = list(logs.stream)\n",
    "\n",
    "    return(marks, streams)\n",
    "\n",
    "def check(tags, marks, tags_i, marks_i, score):\n",
    "    if tags[tags_i] == marks[marks_i]:\n",
    "        score += 1\n",
    "        tags_i += 1\n",
    "        marks_i += 1\n",
    "    else:\n",
    "        tags_i = tags_i - score\n",
    "        marks_i += 1\n",
    "        score = 0\n",
    "    return(tags_i, marks_i, score)\n",
    "\n",
    "def get_index_of_match(tags, marks, window):\n",
    "    for tags_i in range(len(tags) - window):\n",
    "        for marks_i in range(len(marks) - window):\n",
    "            tags_set = tuple(tags[tags_i:tags_i+window])\n",
    "            marks_set = tuple(marks[marks_i:marks_i+window])\n",
    "            if tags_set == marks_set:\n",
    "                print(f'Match found! tags_i: {tags_i}; marks_i: {marks_i}')\n",
    "                print(f'tags_set: {tags_set}')\n",
    "                print(f'marks_set: {marks_set}')\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "\n",
    "    if not found:\n",
    "        raise ValueError('No match found!')\n",
    "    if tuple(tags[tags_i:len(tags)]) != tuple(marks[marks_i:marks_i + len(tags)]): # length of marks should always >= length of tags\n",
    "        raise ValueError('Event tags do not match log file tags!')\n",
    "    return(tags_i, marks_i)\n",
    "\n",
    "def make_tags_hierarchical(streams, tags):\n",
    "\n",
    "    # Change stream string value from 'r' and 'l' into 1 and 2\n",
    "    stream_tag = streams.replace(['r', 'l'], [1, 2])\n",
    "    stream_tag = list(stream_tag)\n",
    "\n",
    "    # Concat stream tags with event tags\n",
    "    hier_tags = []\n",
    "    hier_tags.insert(0, 99999)\n",
    "    for stream, tag in zip(stream_tag, tags):\n",
    "        hier_tag = int(str(stream) + str(tag))\n",
    "        hier_tags.append(hier_tag)\n",
    "\n",
    "    return(hier_tags)\n",
    "\n",
    "def add_hierarchical_tags_to_events(events, hier_tags):\n",
    "    hier_events = []\n",
    "    for i in range(0, len(events)):\n",
    "        hier_event = list(events[i])\n",
    "        hier_event[2] = hier_tags[i]\n",
    "        hier_events.append(hier_event)\n",
    "    return(hier_events)\n",
    "\n",
    "# sub = 9\n",
    "# eeg_fpath = '../data/raw/sub-9.vhdr'\n",
    "# raw = mne.io.read_raw(eeg_fpath)\n",
    "# events, event_ids = mne.events_from_annotations(raw)\n",
    "# events_new = add_stream_to_event_tags(events, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4cd4745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/logs/sub-24_blk-2.log\n",
      "../data/logs/sub-24_blk-4.log\n",
      "../data/logs/sub-24_blk-0.log\n",
      "../data/logs/sub-24_blk-1.log\n",
      "../data/logs/sub-24_blk-3.log\n",
      "Match found! tags_i: 0; marks_i: 0\n",
      "tags_set: (12, 12, 12, 11, 11, 13, 23, 22, 21, 13, 31, 23, 21, 22, 31, 22, 11, 32, 12, 12)\n",
      "marks_set: (12, 12, 12, 11, 11, 13, 23, 22, 21, 13, 31, 23, 21, 22, 31, 22, 11, 32, 12, 12)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Event tags do not match log file tags!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Find the indexes that match event and log tags up\u001b[39;00m\n\u001b[1;32m      9\u001b[0m window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m---> 10\u001b[0m tags_i, marks_i \u001b[38;5;241m=\u001b[39m \u001b[43mget_index_of_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Trim marks to match event tags\u001b[39;00m\n\u001b[1;32m     13\u001b[0m start_i \u001b[38;5;241m=\u001b[39m marks_i\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mget_index_of_match\u001b[0;34m(tags, marks, window)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo match found!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tags[tags_i:\u001b[38;5;28mlen\u001b[39m(tags)]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(marks[marks_i:marks_i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(tags)]): \u001b[38;5;66;03m# length of marks will always >= length of tags\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent tags do not match log file tags!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(tags_i, marks_i)\n",
      "\u001b[0;31mValueError\u001b[0m: Event tags do not match log file tags!"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for i in range(1, len(events)):\n",
    "    tags.append(events[i][2])\n",
    "\n",
    "# Get marks from log files\n",
    "marks, streams = get_marks_and_streams_from_log_file(sub)\n",
    "\n",
    "# Find the indexes that match event and log tags up\n",
    "window = 20\n",
    "tags_i, marks_i = get_index_of_match(tags, marks, window)\n",
    "\n",
    "# Trim marks to match event tags\n",
    "start_i = marks_i\n",
    "end_i = marks_i + len(tags)\n",
    "marks = marks[start_i:end_i]\n",
    "streams = streams[start_i:end_i]\n",
    "\n",
    "# Add stream to tag\n",
    "hier_tags = make_tags_hierarchical(streams, tags)\n",
    "\n",
    "# Add hierarchical tags to events object\n",
    "hier_events = add_hierarchical_tags_to_events(events, hier_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04f8ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       12\n",
      "1       12\n",
      "2       12\n",
      "3       11\n",
      "4       11\n",
      "        ..\n",
      "1807    33\n",
      "1808    13\n",
      "1809    13\n",
      "1810    23\n",
      "1811    23\n",
      "Name: mark, Length: 1812, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2688c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 33, 32, 12, 23, 31, 22, 22, 22, 22, 23, 31, 33, 21, 32, 33, 13, 13, 23, 23]\n",
      "1792    21\n",
      "1793    33\n",
      "1794    32\n",
      "1795    12\n",
      "1796    23\n",
      "1797    31\n",
      "1798    22\n",
      "1799    22\n",
      "1800    22\n",
      "1801    22\n",
      "1802    23\n",
      "1803    31\n",
      "1804    33\n",
      "1805    21\n",
      "1806    32\n",
      "1807    33\n",
      "1808    13\n",
      "1809    13\n",
      "1810    23\n",
      "1811    23\n",
      "Name: mark, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tags[-20:])\n",
    "print(marks[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c660552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1835"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ba4500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1812"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(list(marks))\n",
    "len(marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9596ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lcs_len(text1, text2):\n",
    "    \"\"\"Computes a table of f(i, j) results.\"\"\"\n",
    "    n = len(text1)\n",
    "    m = len(text2)\n",
    "\n",
    "    # We store the results in a (n + 1) x (m + 1) matrix. The +1s are to\n",
    "    # allocate space for the empty strings. Cell [i][j] will cache the\n",
    "    # result of f(i, j).\n",
    "    lcs = [[None for _ in range(m + 1)]\n",
    "               for _ in range(n + 1)]\n",
    "\n",
    "    # We then fill the matrix by going through all rows, using the fact\n",
    "    # that each call only needs results from the previous (i - 1) or\n",
    "    # same (i) row, and from the previous (j - 1) or same (j) column.\n",
    "    for i in range(0, n + 1):\n",
    "        for j in range(0, m + 1):\n",
    "          # The remaining code is exactly the same recursion as before, but\n",
    "          # we do not make recursive calls and instead use the results cached\n",
    "          # in the matrix.\n",
    "            if i == 0 or j == 0:\n",
    "                lcs[i][j] = 0\n",
    "            elif text1[i - 1] == text2[j - 1]:\n",
    "                lcs[i][j] = 1 + lcs[i - 1][j - 1]\n",
    "            else:\n",
    "                lcs[i][j] = max(lcs[i - 1][j], lcs[i][j - 1])\n",
    "\n",
    "    return lcs\n",
    "\n",
    "def diff(text1, text2):\n",
    "    \"\"\"Computes the optimal diff of the two given inputs.\n",
    "\n",
    "    The result is a list where all elements are Removals, Additions or\n",
    "    Unchanged elements.\n",
    "    \"\"\"\n",
    "    lcs = compute_lcs_len(text1, text2)\n",
    "    results = []\n",
    "\n",
    "    i = len(text1)\n",
    "    j = len(text2)\n",
    "\n",
    "  # We iterate until we reach the end of both texts.\n",
    "    while i != 0 or j != 0:\n",
    "        # If we reached the end of one of text1 (i == 0) or text2 (j == 0),\n",
    "        # then we just need to print the remaining additions and removals.\n",
    "        if i == 0:\n",
    "            results.append(('addition', text2[j - 1]))\n",
    "            j -= 1\n",
    "        elif j == 0:\n",
    "            results.append(('removal', text1[i - 1]))\n",
    "            i -= 1\n",
    "        # Otherwise there's still parts of text1 and text2 left. If the\n",
    "        # currently considered parts are equal, then we found an unchanged\n",
    "        # part which belongs to the longest common subsequence.\n",
    "        elif text1[i - 1] == text2[j - 1]:\n",
    "            results.append(('unchanged', text1[i - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        # In any other case, we go in the direction of the longest common\n",
    "        # subsequence.\n",
    "        elif lcs[i - 1][j] <= lcs[i][j - 1]:\n",
    "            results.append(('addition', text2[j - 1]))\n",
    "            j -= 1\n",
    "        else:\n",
    "            results.append(('removal', text1[i - 1]))\n",
    "            i -= 1\n",
    "\n",
    "    # Reverse results because we iterated over the texts from the end but\n",
    "    # want the results to be in forward order.\n",
    "    return list(reversed(results))\n",
    "\n",
    "diffs = diff(list(marks), list(tags))\n",
    "\n",
    "# If there is an addition (a marker that is in tags but not marks), drop those tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f63039f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_drop = []\n",
    "for i, tup in enumerate(diffs):\n",
    "    if tup[0] == 'unchanged':\n",
    "        continue\n",
    "    elif tup[0] == 'addition':\n",
    "        indexes_to_drop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb652b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[119,\n",
       " 120,\n",
       " 121,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461d2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409be0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94f225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5c13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09c50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054baff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb947e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.io.preprocessing import *\n",
    "import mne\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7533266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from ../data/raw/sub-9.vhdr...\n",
      "Setting channel info structure...\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S 11', 'Stimulus/S 12', 'Stimulus/S 13', 'Stimulus/S 21', 'Stimulus/S 22', 'Stimulus/S 23', 'Stimulus/S 31', 'Stimulus/S 32', 'Stimulus/S 33']\n"
     ]
    }
   ],
   "source": [
    "# Get events from raw data\n",
    "sub = 9\n",
    "eeg_fpath = '../data/raw/sub-9.vhdr'\n",
    "raw = mne.io.read_raw(eeg_fpath)\n",
    "events, event_ids = mne.events_from_annotations(raw)\n",
    "\n",
    "# Extract tags from events\n",
    "tags = []\n",
    "for i in range(1, len(events)):\n",
    "    tags.append(events[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573b4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d49ba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/logs/sub-9_blk-4.log\n",
      "../data/logs/sub-9_blk-2.log\n",
      "../data/logs/sub-9_blk-3.log\n",
      "../data/logs/sub-9_blk-1.log\n",
      "../data/logs/sub-9_blk-0.log\n"
     ]
    }
   ],
   "source": [
    "# Get events from log files\n",
    "log_dir = '../data/logs'\n",
    "logs = pd.DataFrame()\n",
    "\n",
    "for fpath in list(glob.glob(f'{log_dir}/sub-{sub}_*.log')):\n",
    "\n",
    "    # checking if it is a file\n",
    "    print(fpath)\n",
    "    if os.path.isfile(fpath):\n",
    "        log = pd.read_csv(fpath)\n",
    "        logs = pd.concat([logs, log])\n",
    "\n",
    "logs = logs.sort_values(by = ['block_num', 'seq_num', 'tone_num'])\n",
    "logs = logs.reset_index()\n",
    "marks = logs.mark\n",
    "streams = logs.stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db03cc6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d29e4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found! tags_i: 0; marks_i: 50\n",
      "tags_set: (31, 13, 12, 12, 33, 23, 32, 23, 33, 33, 33, 21, 31, 12, 33, 23, 13, 12, 13, 12)\n",
      "marks_set: (31, 13, 12, 12, 33, 23, 32, 23, 33, 33, 33, 21, 31, 12, 33, 23, 13, 12, 13, 12)\n",
      "TIME: 0.0058002471923828125\n"
     ]
    }
   ],
   "source": [
    "# Iterate over tags in exponential time\n",
    "t0 = time.time()\n",
    "\n",
    "window = 20\n",
    "for tags_i in range(len(tags) - window):\n",
    "    for marks_i in range(len(marks) - window):\n",
    "        tags_set = tuple(tags[tags_i:tags_i+window])\n",
    "        marks_set = tuple(marks[marks_i:marks_i+window])\n",
    "        if tags_set == marks_set:\n",
    "            print(f'Match found! tags_i: {tags_i}; marks_i: {marks_i}')\n",
    "            print(f'tags_set: {tags_set}')\n",
    "            print(f'marks_set: {marks_set}')\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        break\n",
    "        \n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"TIME: {t1-t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "37f7be6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found! tags_i: 20; marks_i: 70\n",
      "tags_set: (31, 13, 12, 12, 33, 23, 32, 23, 33, 33, 33, 21, 31, 12, 33, 23, 13, 12, 13, 12)\n",
      "marks_set: (31, 13, 12, 12, 33, 23, 32, 23, 33, 33, 33, 21, 31, 12, 33, 23, 13, 12, 13, 12)\n",
      "TIME: 0.003219127655029297\n"
     ]
    }
   ],
   "source": [
    "# Iterate over tags in linear time\n",
    "t0 = time.time()\n",
    "\n",
    "window = 20\n",
    "\n",
    "def check(tags, marks, tags_i, marks_i, score):\n",
    "    if tags[tags_i] == marks[marks_i]:\n",
    "        score += 1\n",
    "        tags_i += 1\n",
    "        marks_i += 1\n",
    "    else:\n",
    "        tags_i = tags_i - score\n",
    "        marks_i += 1\n",
    "        score = 0\n",
    "    return(tags_i, marks_i, score)\n",
    "\n",
    "score = 0\n",
    "marks_i = 0\n",
    "for tags_i in range(len(tags) - window):\n",
    "    while score < window:\n",
    "        tags_i, marks_i, score = check(tags, marks, tags_i, marks_i, score)\n",
    "    if score == window:\n",
    "        print(f'Match found! tags_i: {tags_i}; marks_i: {marks_i}')\n",
    "        print(f'tags_set: {tags_set}')\n",
    "        print(f'marks_set: {marks_set}')\n",
    "        break\n",
    "        \n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"TIME: {t1-t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cbe05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim marks to match event tags\n",
    "start_i = marks_i\n",
    "end_i = marks_i + len(tags)\n",
    "marks = marks[start_i:end_i]\n",
    "streams = streams[start_i:end_i]\n",
    "\n",
    "# Aggressive check\n",
    "if not found:\n",
    "    raise ValueError('No match found!')\n",
    "if tuple(tags[tags_i:len(tags)]) != tuple(marks): # length of marks will always >= length of tags\n",
    "    raise ValueError('Event tags do not match log file tags!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ccd43af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make event tags hierarchical\n",
    "\n",
    "# Change stream string value from 'r' and 'l' into 1 and 2\n",
    "stream_tag = streams.replace(['r', 'l'], [1, 2])\n",
    "stream_tag = list(stream_tag)\n",
    "\n",
    "# Concat stream tags with event tags\n",
    "hier_tags = []\n",
    "hier_tags.insert(0, 99999)\n",
    "for stream, tag in zip(stream_tag, tags):\n",
    "    hier_tag = int(str(stream) + str(tag))\n",
    "    hier_tags.append(hier_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4f06d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return new events object\n",
    "hier_events = []\n",
    "for i in range(0, len(events)):\n",
    "    hier_event = list(events[i])\n",
    "    hier_event[2] = hier_tags[i]\n",
    "    hier_events.append(hier_event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
